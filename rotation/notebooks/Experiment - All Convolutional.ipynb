{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/facundo/.python/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import datasets\n",
    "import models\n",
    "dataset=\"cifar10\"\n",
    "(x_train, y_train), (x_test, y_test), input_shape,num_classes = datasets.get_data(dataset)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 10)          1290      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 613,386\n",
      "Trainable params: 611,722\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.all_conv(input_shape,num_classes,filters=64)\n",
    "sgd = keras.optimizers.SGD(lr=0.001, decay=1e-8, momentum=0.9, nesterov=True)\n",
    "opt=keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_181 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_184 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 8, 8, 10)          1290      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_21  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 613,386\n",
      "Trainable params: 611,722\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rotated_model = models.all_conv(input_shape,num_classes,filters=64)\n",
    "sgd = keras.optimizers.SGD(lr=0.25, decay=1e-3, momentum=0.9, nesterov=True)\n",
    "opt=keras.optimizers.RMSprop(lr=0.001)\n",
    "\n",
    "rotated_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "print(rotated_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with unrotated dataset...\n",
      "Epoch 1/5\n",
      "1563/1562 [==============================] - 18s 12ms/step - loss: 0.1063 - acc: 0.9629 - val_loss: 0.6870 - val_acc: 0.8298\n",
      "Epoch 2/5\n",
      "1563/1562 [==============================] - 18s 12ms/step - loss: 0.0943 - acc: 0.9672 - val_loss: 0.8258 - val_acc: 0.8168\n",
      "Epoch 3/5\n",
      "1563/1562 [==============================] - 18s 12ms/step - loss: 0.0884 - acc: 0.9696 - val_loss: 0.7528 - val_acc: 0.8274\n",
      "Epoch 4/5\n",
      "1563/1562 [==============================] - 18s 12ms/step - loss: 0.0827 - acc: 0.9716 - val_loss: 0.7752 - val_acc: 0.8283\n",
      "Epoch 5/5\n",
      "1563/1562 [==============================] - 18s 12ms/step - loss: 0.0754 - acc: 0.9738 - val_loss: 0.8546 - val_acc: 0.8261\n",
      "Training rotated model with rotated dataset...\n",
      "Epoch 1/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.9482 - acc: 0.6663 - val_loss: 1.0020 - val_acc: 0.6538\n",
      "Epoch 2/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.9290 - acc: 0.6768 - val_loss: 0.9513 - val_acc: 0.6697\n",
      "Epoch 3/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.9082 - acc: 0.6827 - val_loss: 0.9504 - val_acc: 0.6698\n",
      "Epoch 4/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8943 - acc: 0.6878 - val_loss: 0.9203 - val_acc: 0.6834\n",
      "Epoch 5/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8837 - acc: 0.6921 - val_loss: 0.9337 - val_acc: 0.6752\n",
      "Epoch 6/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8609 - acc: 0.6993 - val_loss: 0.9333 - val_acc: 0.6781\n",
      "Epoch 7/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8531 - acc: 0.7022 - val_loss: 0.9088 - val_acc: 0.6831\n",
      "Epoch 8/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8374 - acc: 0.7091 - val_loss: 0.9239 - val_acc: 0.6728\n",
      "Epoch 9/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8237 - acc: 0.7112 - val_loss: 0.8804 - val_acc: 0.6990\n",
      "Epoch 10/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8103 - acc: 0.7183 - val_loss: 0.8562 - val_acc: 0.7049\n",
      "Epoch 11/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.8032 - acc: 0.7216 - val_loss: 0.8491 - val_acc: 0.7044\n",
      "Epoch 12/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.7905 - acc: 0.7235 - val_loss: 0.9103 - val_acc: 0.6825\n",
      "Epoch 13/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.7807 - acc: 0.7287 - val_loss: 0.8918 - val_acc: 0.6947\n",
      "Epoch 14/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.7671 - acc: 0.7340 - val_loss: 0.8244 - val_acc: 0.7161\n",
      "Epoch 15/15\n",
      "1563/1562 [==============================] - 20s 13ms/step - loss: 0.7612 - acc: 0.7369 - val_loss: 0.8475 - val_acc: 0.7052\n",
      "Testing both models on both datasets...\n",
      "model_rotated_test_dataset score: loss=6.139791, accuracy=0.302600\n",
      "model_rotated_train_dataset score: loss=6.105164, accuracy=0.308260\n",
      "model_test_dataset score: loss=0.854639, accuracy=0.826100\n",
      "model_train_dataset score: loss=0.060216, accuracy=0.979180\n",
      "rotated_model_rotated_test_dataset score: loss=0.844585, accuracy=0.710500\n",
      "rotated_model_rotated_train_dataset score: loss=0.756190, accuracy=0.734200\n",
      "rotated_model_test_dataset score: loss=0.798629, accuracy=0.726300\n",
      "rotated_model_train_dataset score: loss=0.709101, accuracy=0.750500\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "batch_size = 32\n",
    "# 10 for cifar10, 2 for mnist, 5 for fashion_mnist, 10 for cluttered_mnist\n",
    "epochs={'cifar10':5,'mnist':5,'fashion_mnist':12,'cluttered_mnist':10,'lsa16':20,\"pugeault\":30}\n",
    "\n",
    "rotated_epochs={'cifar10':15,'mnist':5,'fashion_mnist':60,'cluttered_mnist':30,'lsa16':100,\"pugeault\":40}\n",
    "\n",
    "scores=experiment.train_rotated(model,rotated_model,x_train,y_train,x_test,\n",
    "                          y_test,num_classes,input_shape,batch_size,epochs[dataset],rotated_epochs[dataset])\n",
    "\n",
    "for k,v in scores.items():\n",
    "    print('%s score: loss=%f, accuracy=%f' % (k,v[0],v[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-08 22:23:03.839870\n",
      "Results on dataset cifar10 with model all_conv and rotated model all_conv\n",
      "\n",
      "model_rotated_test_dataset score: loss=5.131983, accuracy=0.299800\n",
      "\n",
      "model_rotated_train_dataset score: loss=5.077612, accuracy=0.309880\n",
      "\n",
      "model_test_dataset score: loss=0.693172, accuracy=0.824500\n",
      "\n",
      "model_train_dataset score: loss=0.065184, accuracy=0.978440\n",
      "\n",
      "rotated_model_rotated_test_dataset score: loss=0.997997, accuracy=0.650800\n",
      "\n",
      "rotated_model_rotated_train_dataset score: loss=0.961354, accuracy=0.663040\n",
      "\n",
      "rotated_model_test_dataset score: loss=0.969987, accuracy=0.659000\n",
      "\n",
      "rotated_model_train_dataset score: loss=0.918451, accuracy=0.674920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "output_file=\"results/all_conv.txt\"\n",
    "f= open(output_file,\"a+\")\n",
    "general_message=\"%s\\nResults on dataset %s with model %s and rotated model %s\\n\" % (str(datetime.now()),dataset,model.name,rotated_model.name)\n",
    "f.write(general_message)\n",
    "print(general_message)\n",
    "for k,v in scores.items():\n",
    "    message='%s score: loss=%f, accuracy=%f\\n' % (k,v[0],v[1])\n",
    "    print(message)\n",
    "    f.write(message)\n",
    "f.write(\"\\n\\n\")    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
