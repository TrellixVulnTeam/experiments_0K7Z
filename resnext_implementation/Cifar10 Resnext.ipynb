{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Activation', 'BatchNormalization', 'CIFAR_TF_WEIGHTS_PATH', 'CIFAR_TF_WEIGHTS_PATH_NO_TOP', 'CIFAR_TH_WEIGHTS_PATH', 'CIFAR_TH_WEIGHTS_PATH_NO_TOP', 'Conv2D', 'Dense', 'GlobalAveragePooling2D', 'GlobalMaxPooling2D', 'IMAGENET_TF_WEIGHTS_PATH', 'IMAGENET_TF_WEIGHTS_PATH_NO_TOP', 'IMAGENET_TH_WEIGHTS_PATH', 'IMAGENET_TH_WEIGHTS_PATH_NO_TOP', 'Input', 'K', 'Lambda', 'MaxPooling2D', 'Model', 'ResNextImageNet', '__bottleneck_block', '__builtins__', '__cached__', '__create_res_next', '__create_res_next_imagenet', '__file__', '__grouped_convolution_block', '__initial_conv_block', '__initial_conv_block_imagenet', '__loader__', '__name__', '__package__', '__spec__', '_obtain_input_shape', 'add', 'concatenate', 'convert_all_kernels_in_model', 'get_file', 'get_source_inputs', 'l2', 'residual_network', 'warnings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of modelresnext failed: Traceback (most recent call last):\n",
      "  File \"/data/dev/experiments/.env/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/data/dev/experiments/.env/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 626, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 767, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 727, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n",
      "  File \"/data/dev/experiments/resnext_implementation/modelresnext.py\", line 87\n",
      "    raise ValueError('Depth of the network must be such that (depth - 2)'\n",
      "                                                                        ^\n",
      "TabError: inconsistent use of tabs and spaces in indentation\n",
      "]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Depth of the network must be such that (depth - 2)should be divisible by 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-315a4ec4be17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"mine\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weights/mine.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodelresnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weights/other.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dev/experiments/resnext_implementation/modelresnext.py\u001b[0m in \u001b[0;36mresidual_network\u001b[0;34m(input_shape, depth, cardinality, width, weight_decay, include_top, weights, input_tensor, pooling, classes)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \traise ValueError('Depth of the network must be such that (depth - 2)'\n\u001b[0m\u001b[1;32m     88\u001b[0m                              'should be divisible by 9.')\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Depth of the network must be such that (depth - 2)should be divisible by 9."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import modelresnext as modelresnext\n",
    "print(dir(modelresnext))\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "\n",
    "img_dim = (img_channels, img_rows, img_cols) if K.image_dim_ordering() == \"th\" else (img_rows, img_cols, img_channels)\n",
    "depth = 29\n",
    "cardinality = 8\n",
    "width = 16\n",
    "\n",
    "model = \"mine\" # \"other\"\n",
    "if model== \"mine\":\n",
    "    weights_file = \"weights/mine.h5\"\n",
    "    model= modelresnext.residual_network(img_dim,nb_classes,cardinality,width)\n",
    "else:\n",
    "    weights_file = \"weights/other.h5\"\n",
    "    model = modelresnext.residual_network(img_dim, depth=depth, cardinality=cardinality, width=width, weights=None, classes=nb_classes)\n",
    "\n",
    "print(\"Model created\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(lr=1e-3)  # Using Adam instead of SGD to speed up training\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "print(\"Building model...\")\n",
    "\n",
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "\n",
    "trainX /= 255.\n",
    "testX /= 255.\n",
    "\n",
    "Y_train = np_utils.to_categorical(trainY, nb_classes)\n",
    "Y_test = np_utils.to_categorical(testY, nb_classes)\n",
    "\n",
    "generator = ImageDataGenerator(rotation_range=15,\n",
    "                               width_shift_range=5./32,\n",
    "                               height_shift_range=5./32,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "generator.fit(trainX, seed=0)\n",
    "\n",
    "out_dir = \"weights/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Load model\n",
    "\n",
    "\n",
    "if False and os.path.exists(weights_file):\n",
    "    model.load_weights(weights_file)\n",
    "    print(\"Model loaded.\")\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1),\n",
    "                               cooldown=0, patience=10, min_lr=1e-6)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(weights_file, monitor=\"val_acc\", save_best_only=True,\n",
    "                                   save_weights_only=True, mode='auto')\n",
    "\n",
    "callbacks = [lr_reducer, model_checkpoint]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 237s 609ms/step - loss: 1.9653 - acc: 0.2718 - val_loss: 1.6992 - val_acc: 0.3815\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.6807 - acc: 0.3789 - val_loss: 1.4729 - val_acc: 0.4636\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.5523 - acc: 0.4317 - val_loss: 1.4179 - val_acc: 0.4762\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.4801 - acc: 0.4585 - val_loss: 1.3368 - val_acc: 0.5072\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.4296 - acc: 0.4789 - val_loss: 1.2762 - val_acc: 0.5346\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.3796 - acc: 0.4973 - val_loss: 1.2366 - val_acc: 0.5501\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.3475 - acc: 0.5122 - val_loss: 1.2271 - val_acc: 0.5553\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.3137 - acc: 0.5242 - val_loss: 1.1602 - val_acc: 0.5777\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.2821 - acc: 0.5337 - val_loss: 1.1636 - val_acc: 0.5805\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2666 - acc: 0.5388 - val_loss: 1.1356 - val_acc: 0.5900\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2476 - acc: 0.5507 - val_loss: 1.1288 - val_acc: 0.5911\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2307 - acc: 0.5540 - val_loss: 1.0918 - val_acc: 0.6057\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2163 - acc: 0.5644 - val_loss: 1.0795 - val_acc: 0.6078\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2055 - acc: 0.5628 - val_loss: 1.1414 - val_acc: 0.5899\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1839 - acc: 0.5721 - val_loss: 1.0986 - val_acc: 0.6082\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1803 - acc: 0.5753 - val_loss: 1.0561 - val_acc: 0.6173\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1623 - acc: 0.5818 - val_loss: 1.0482 - val_acc: 0.6226\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.1531 - acc: 0.5847 - val_loss: 1.0526 - val_acc: 0.6198\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1535 - acc: 0.5850 - val_loss: 1.0190 - val_acc: 0.6326\n",
      "Epoch 20/100\n",
      "154/390 [==========>...................] - ETA: 2:21 - loss: 1.1409 - acc: 0.5903"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "model.fit_generator(generator.flow(trainX, Y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(trainX) // batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(testX, Y_test),\n",
    "                    validation_steps=testX.shape[0] // batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yPreds = model.predict(testX)\n",
    "yPred = np.argmax(yPreds, axis=1)\n",
    "yTrue = testY\n",
    "\n",
    "accuracy = metrics.accuracy_score(yTrue, yPred) * 100\n",
    "error = 100 - accuracy\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Error : \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
